{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#read the data\n",
    "data = pd.read_csv('seed.csv')\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dependent variable class equ to numeric value\n",
    "factor = pd.factorize(data['_Category'])\n",
    "data._Category = factor[0]\n",
    "definitions = factor[1]\n",
    "#print(data._Category.head())\n",
    "#print(definitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train and test data 70-30 ratio\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(data['_Body'],data['_Category'],train_size = 0.70, test_size = 0.30)\n",
    "#print(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector feature count\n",
    "vect = CountVectorizer().fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "#print(X_train_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=500, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logisitic model analysis\n",
    "model = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial', max_iter=500)\n",
    "#print(max_value)\n",
    "#print(Y_train)\n",
    "model.fit(X_train_vectorized, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "#vect = CountVectorizer().fit(X_valid)\n",
    "X_valid_vectorized = vect.transform(X_valid)\n",
    "\n",
    "#predictions = model.predict_proba(X_valid_vectorized)\n",
    "#print(predictions)\n",
    "#Y_valid = Y_valid*10 \n",
    "print(model.score(X_valid_vectorized,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vect.joblib']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "joblib.dump(model,'model.joblib')\n",
    "# save CountVectorizer() to disk\n",
    "joblib.dump(vect,'vect.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['vect_tf_idf.joblib']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analysis with Tf-idf vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "vect_tf_idf = vectorizer.fit(X_train)\n",
    "X_train_vec_tf_idf = vect_tf_idf.transform(X_train)\n",
    "model.fit(X_train_vec_tf_idf, Y_train)\n",
    "print(model.score(vect_tf_idf.transform(X_valid),Y_valid))\n",
    "#dump Tfid\n",
    "joblib.dump(vectorizer,'vect_tf_idf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nbv.joblib']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training a Naive Bayes classifier \n",
    "\n",
    "nbv = GaussianNB()\n",
    "nbv = nbv.fit(X_train_vectorized.toarray(), Y_train) \n",
    "print(nbv.score(vect.transform(X_valid).toarray(),Y_valid))\n",
    "joblib.dump(nbv,'nbv.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "nb_tf_idf = nbv.fit(X_train_vec_tf_idf.toarray(), Y_train) \n",
    "print(nb_tf_idf.score(vect_tf_idf.transform(X_valid).toarray(),Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['classifier.joblib']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 53)\n",
    "classifier.fit(X_train_vectorized, Y_train)\n",
    "# Predicting the valid set results\n",
    "Y_pred = classifier.predict(X_valid_vectorized)\n",
    "print(accuracy_score(Y_valid, Y_pred))\n",
    "joblib.dump(classifier,'classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23333333333333334\n"
     ]
    }
   ],
   "source": [
    "#Fitting  tf-idf features\n",
    "classifier.fit(X_train_vec_tf_idf, Y_train)\n",
    "#Predicitng the valid test results\n",
    "Y_pred = classifier.predict(vect_tf_idf.transform(X_valid))\n",
    "print(accuracy_score(Y_valid, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jaccard similarity to find out similarity between two texts\n",
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "#token1 = data.loc[0,'_Body']\n",
    "#token2 = input_data.loc[0,'_Body']\n",
    "#print(get_jaccard_sim(token1,token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read input data\n",
    "input_data = pd.read_csv('input_data.csv')\n",
    "#print(input_data)\n",
    "input_data['_Category'] = 0\n",
    "data['_Body'] = data['_Body'].astype(str) #Convert to string \n",
    "input_data['_Body'] = input_data['_Body'].astype(str) #Convert to string\n",
    "\n",
    "#Categorize body of input data by jaccard similarity \n",
    "for i in range(len(input_data)):\n",
    "    max_value = -1\n",
    "    for j in range(len(data)):\n",
    "        js = get_jaccard_sim(input_data.loc[i,'_Body'],data.loc[j,'_Body'])\n",
    "        if max_value < js:\n",
    "            max_value = js\n",
    "            input_data.loc[i,'_Category'] = data.loc[j,'_Category']\n",
    "        if max_value == 1:\n",
    "            input_data.loc[i,'_Category'] = data.loc[j,'_Category']\n",
    "            break\n",
    "#print(input_data['Category_Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data from the input.csv\n",
    "testX = input_data['_Body']\n",
    "testY = input_data['_Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35129740518962077"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(testX)\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load('model.joblib')\n",
    "# load the CountVectorizer()\n",
    "vect = joblib.load('vect.joblib')\n",
    "#transform the test data to the corresponding vectorizer\n",
    "X_train_vectorized = vect.transform(testX)\n",
    "\n",
    "loaded_model.predict(X_train_vectorized)\n",
    "loaded_model.score(X_train_vectorized,testY)\n",
    "#loaded_model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09181636726546906"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#load the tf-idf vectorizer\n",
    "vect_tf_idf = joblib.load('vect_tf_idf.joblib')\n",
    "X_train_vec_tf_idf = vect_tf_idf.transform(testX)\n",
    "#loaded_model.predict(X_train_vec_tf_idf)\n",
    "loaded_model.score(X_train_vec_tf_idf,testY)\n",
    "#loaded_model.close()\n",
    "#model.fit(X_train_vec_tf_idf, Y_train)\n",
    "#model.predict(X_train_vec_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35728542914171657\n",
      "0.35728542914171657\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes classifier analysis with the test data\n",
    "\n",
    "nbv = joblib.load('nbv.joblib')\n",
    "print(nbv.score(X_train_vectorized.toarray(),testY))\n",
    "print(nbv.score(X_train_vec_tf_idf.toarray(),testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3033932135728543\n"
     ]
    }
   ],
   "source": [
    "#load the random forest classifier\n",
    "classifier = joblib.load('classifier.joblib')\n",
    "Y_pred = classifier.predict(X_train_vectorized)\n",
    "print(accuracy_score(testY, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09181636726546906\n"
     ]
    }
   ],
   "source": [
    "# random forest analysis with tf-idf vectorizer()\n",
    "Y_pred = classifier.predict(X_train_vec_tf_idf)\n",
    "print(accuracy_score(testY, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
